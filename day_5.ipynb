{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXOygyxnTn9OdGIGvs+AVA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/creation-extro/ai-nlp/blob/main/day_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93LgFj2RkZfH",
        "outputId": "9324667d-5240-4a43-ee22-763a7af0ecb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: whisper-timestamped in /usr/local/lib/python3.12/dist-packages (1.15.9)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.12.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.32.4)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.37.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from whisper-timestamped) (3.0.12)\n",
            "Requirement already satisfied: dtw-python in /usr/local/lib/python3.12/dist-packages (from whisper-timestamped) (1.7.2)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (from whisper-timestamped) (20250625)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from dtw-python->whisper-timestamped) (1.16.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (0.60.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (2.9.0+cu126)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (3.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper->whisper-timestamped) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper->whisper-timestamped) (2025.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (1.11.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper->whisper-timestamped) (1.3.0)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install moviepy whisper-timestamped spacy pydantic\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper_timestamped as whisper\n",
        "from moviepy.editor import VideoFileClip\n",
        "import json\n",
        "import os\n",
        "import spacy\n",
        "import sys\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# --- LLM OUTPUT STRUCTURE (Day 4 Requirement - Defines the output contract) ---\n",
        "class QuizOption(BaseModel):\n",
        "    text: str = Field(description=\"The text of the answer option.\")\n",
        "    is_correct: bool = Field(description=\"True if this is the correct answer.\")\n",
        "\n",
        "class Question(BaseModel):\n",
        "    question: str = Field(description=\"The multiple-choice question text.\")\n",
        "    options: list[QuizOption] = Field(description=\"A list of 4 possible answers, with exactly one marked as correct.\")\n",
        "\n",
        "# --- INITIALIZE NLP MODEL (Runs once when the backend starts) ---\n",
        "try:\n",
        "    # Load the spaCy model\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except Exception as e:\n",
        "    print(f\"FATAL ERROR: spaCy model not loaded. Please run setup commands. Error: {e}\", file=sys.stderr)\n",
        "    nlp = None\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# HELPER FUNCTION 1: DAY 2 - Transcription\n",
        "# ----------------------------------------------------------------------\n",
        "def get_transcript_data(video_path: str) -> dict | None:\n",
        "    \"\"\"Handles audio extraction and Whisper transcription.\"\"\"\n",
        "\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"ERROR: Video file not found at path: {video_path}\")\n",
        "        return None\n",
        "\n",
        "    temp_audio_path = \"temp_audio_mahesh.mp3\"\n",
        "\n",
        "    # Extract audio\n",
        "    try:\n",
        "        video_clip = VideoFileClip(video_path)\n",
        "        video_clip.audio.write_audiofile(temp_audio_path, logger=None)\n",
        "        video_clip.close()\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Audio extraction failed. Error: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Transcribe\n",
        "    result = None\n",
        "    try:\n",
        "        model = whisper.load_model(\"small\")\n",
        "        result = whisper.transcribe(model, temp_audio_path, language=\"en\", verbose=False)\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Whisper transcription failed. Error: {e}\")\n",
        "\n",
        "    # Clean up the temporary audio file\n",
        "    if os.path.exists(temp_audio_path):\n",
        "        os.remove(temp_audio_path)\n",
        "\n",
        "    return result\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# HELPER FUNCTION 2: DAY 3 - Topic Detection\n",
        "# ----------------------------------------------------------------------\n",
        "def get_topic_triggers(transcript_data: dict) -> list:\n",
        "    \"\"\"Analyzes segments for key nouns/concepts to determine quiz trigger points.\"\"\"\n",
        "    if not nlp:\n",
        "        print(\"ERROR: Cannot run topic detection. spaCy model not initialized.\")\n",
        "        return []\n",
        "\n",
        "    topic_segments = []\n",
        "\n",
        "    for segment in transcript_data.get('segments', []):\n",
        "        text = segment['text'].strip()\n",
        "        if not text: continue\n",
        "\n",
        "        start_time = segment['start']\n",
        "        doc = nlp(text)\n",
        "\n",
        "        # Extract Key Nouns/Concepts (Revised logic for technical topics)\n",
        "        current_concepts = {\n",
        "            token.text.lower()\n",
        "            for token in doc\n",
        "            if token.pos_ in ('NOUN', 'PROPN') and not token.is_stop and token.is_alpha\n",
        "        }\n",
        "\n",
        "        if current_concepts:\n",
        "            concept_list = list(current_concepts)[:5]\n",
        "            topic_segments.append({\n",
        "                \"start_sec\": int(start_time),\n",
        "                \"topic_text\": text, # Provide the full text for LLM question generation\n",
        "                \"key_concepts\": \" | \".join(concept_list),\n",
        "            })\n",
        "\n",
        "    return topic_segments\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# HELPER FUNCTION 3: DAY 4 - LLM Output Mapping\n",
        "# ----------------------------------------------------------------------\n",
        "def map_llm_output_to_quiz_json(llm_output_text: str, trigger_time_sec: int) -> dict:\n",
        "    \"\"\"Parses raw LLM JSON output into the final application JSON structure.\"\"\"\n",
        "\n",
        "    try:\n",
        "        llm_data = json.loads(llm_output_text)\n",
        "        validated_question = Question(**llm_data)\n",
        "\n",
        "        return {\n",
        "            \"id\": f\"quiz-{trigger_time_sec}\",\n",
        "            \"trigger_time_sec\": trigger_time_sec,\n",
        "            \"question\": validated_question.question,\n",
        "            \"options\": [opt.model_dump() for opt in validated_question.options]\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: LLM output mapping failed. Check JSON format/Pydantic validation: {e}\")\n",
        "        return {}\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# üéØ MAIN ENTRY POINT FOR THE BACKEND (Day 5 Task Completion)\n",
        "# ----------------------------------------------------------------------\n",
        "def run_full_ml_pipeline(video_path: str, simulated_llm_output: str) -> list[dict]:\n",
        "    \"\"\"\n",
        "    The unified function Tejaswi's backend will call.\n",
        "    It runs the full sequence and returns a list of final quiz objects.\n",
        "\n",
        "    Args:\n",
        "        video_path: Local path to the uploaded video file.\n",
        "        simulated_llm_output: (In production: This step requires a call to Arya's Gemini API logic,\n",
        "                              but here we use a placeholder.)\n",
        "\n",
        "    Returns:\n",
        "        A list of structured quiz dictionaries, or an empty list on failure.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n--- Day 5: Running ML Pipeline for Video: {video_path} ---\")\n",
        "\n",
        "    # 1. DAY 2: Transcription\n",
        "    raw_transcript_data = get_transcript_data(video_path)\n",
        "    if not raw_transcript_data:\n",
        "        print(\"Pipeline aborted at Transcription stage.\")\n",
        "        return []\n",
        "\n",
        "    # 2. DAY 3: Topic Trigger Detection\n",
        "    topic_list = get_topic_triggers(raw_transcript_data)\n",
        "    if not topic_list:\n",
        "        print(\"Pipeline aborted: No topics detected.\")\n",
        "        return []\n",
        "\n",
        "    # 3. DAY 4: Generate Quizzes (Simulated)\n",
        "    # In a real scenario, this loop calls Arya's Gemini API for *each* topic segment.\n",
        "    final_quizzes = []\n",
        "\n",
        "    # We will simulate only the first quiz for this demo\n",
        "    first_topic = topic_list[0]\n",
        "\n",
        "    # NOTE: This is where Tejaswi's API endpoint would call Arya's LLM module,\n",
        "    # passing in first_topic['topic_text'] and receiving the structured JSON output.\n",
        "\n",
        "    final_quiz = map_llm_output_to_quiz_json(\n",
        "        simulated_llm_output,\n",
        "        first_topic['start_sec']\n",
        "    )\n",
        "\n",
        "    if final_quiz:\n",
        "        final_quizzes.append(final_quiz)\n",
        "\n",
        "    print(f\"--- Pipeline Complete. {len(final_quizzes)} quiz(zes) ready. ---\")\n",
        "\n",
        "    return final_quizzes\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# --- DEMO EXECUTION (Simulating Tejaswi's Call) ---\n",
        "# ----------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # --- SIMULATED INPUTS (Update VIDEO_FILE_PATH for real testing) ---\n",
        "    VIDEO_FILE_PATH_DEMO = 'arrays.mp4' # Replace with your test file path\n",
        "\n",
        "    # This must be replaced with a loop calling the actual Gemini API in production\n",
        "    SIMULATED_LLM_OUTPUT_DEMO = \"\"\"\n",
        "    {\n",
        "        \"question\": \"What is the primary benefit of using a small-sized model for transcription?\",\n",
        "        \"options\": [\n",
        "            {\"text\": \"Higher overall accuracy\", \"is_correct\": false},\n",
        "            {\"text\": \"Faster inference and lower hardware requirements\", \"is_correct\": true},\n",
        "            {\"text\": \"Support for more than 50 languages\", \"is_correct\": false},\n",
        "            {\"text\": \"Better handling of complex acoustic environments\", \"is_correct\": false}\n",
        "        ]\n",
        "    }\n",
        "    \"\"\"\n",
        "    # ------------------------------------------------------------------\n",
        "\n",
        "    final_result = run_full_ml_pipeline(\n",
        "        video_path=VIDEO_FILE_PATH_DEMO,\n",
        "        simulated_llm_output=SIMULATED_LLM_OUTPUT_DEMO\n",
        "    )\n",
        "\n",
        "    print(\"\\n\\n--- FINAL OUTPUT SENT TO FRONTEND (Kashish) ---\")\n",
        "    if final_result:\n",
        "        print(json.dumps(final_result, indent=4))\n",
        "        print(f\"\\n‚úÖ SUCCESS: Pipeline returned {len(final_result)} quiz object(s).\")\n",
        "    else:\n",
        "        print(\"\\n‚ùå FAILURE: Pipeline returned an empty list. Check error messages above.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz6t6x2SkeEp",
        "outputId": "d666d928-eaf8-4eaa-851c-28478c1a0d1a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Day 5: Running ML Pipeline for Video: arrays.mp4 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 461M/461M [00:03<00:00, 147MiB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5981/5981 [01:10<00:00, 84.42frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Pipeline Complete. 1 quiz(zes) ready. ---\n",
            "\n",
            "\n",
            "--- FINAL OUTPUT SENT TO FRONTEND (Kashish) ---\n",
            "[\n",
            "    {\n",
            "        \"id\": \"quiz-0\",\n",
            "        \"trigger_time_sec\": 0,\n",
            "        \"question\": \"What is the primary benefit of using a small-sized model for transcription?\",\n",
            "        \"options\": [\n",
            "            {\n",
            "                \"text\": \"Higher overall accuracy\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"Faster inference and lower hardware requirements\",\n",
            "                \"is_correct\": true\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"Support for more than 50 languages\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"Better handling of complex acoustic environments\",\n",
            "                \"is_correct\": false\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "]\n",
            "\n",
            "‚úÖ SUCCESS: Pipeline returned 1 quiz object(s).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1CVzzGp2mf7b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}