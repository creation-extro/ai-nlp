{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/creation-extro/ai-nlp/blob/main/AI%20Content%20Analysis%20%26%20Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy whisper-timestamped spacy pydantic\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxYb9Og9SrrZ",
        "outputId": "41167be7-c34c-4a03-a9cc-3a5d04ca8bc9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: whisper-timestamped in /usr/local/lib/python3.12/dist-packages (1.15.9)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.12.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.32.4)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.37.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from whisper-timestamped) (3.0.12)\n",
            "Requirement already satisfied: dtw-python in /usr/local/lib/python3.12/dist-packages (from whisper-timestamped) (1.7.2)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (from whisper-timestamped) (20250625)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.11.12)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from dtw-python->whisper-timestamped) (1.16.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (0.60.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (2.9.0+cu126)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper->whisper-timestamped) (3.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper->whisper-timestamped) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper->whisper-timestamped) (2025.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->whisper-timestamped) (1.11.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper->whisper-timestamped) (1.3.0)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m126.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IX-sDDhOUOGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e371491c"
      },
      "source": [
        "# Task\n",
        "Generate 3 to 4 multiple-choice quiz questions based on key concepts identified in the `arrays.mp4` video transcript. Each quiz question will feature a question, one correct option derived from the segment's topic, and three incorrect options generated from other noun chunks in the segment or generic placeholders, and be saved to a `all_quizzes.json` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7fd65fe"
      },
      "source": [
        "## Select Multiple Quiz Segments\n",
        "\n",
        "### Subtask:\n",
        "Modify the main execution block to iterate through the `topic_list` and select 3 to 4 distinct segments (or as many as available up to 4) that are suitable for quiz generation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52a1b09e"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying the main execution block to select multiple quiz segments from the `topic_list`. I need to iterate through the `topic_list`, select up to 4 segments, and then call the `map_llm_output_to_quiz_json` function for each selected segment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4b217d3"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous instruction asked to modify the main execution block to select multiple quiz segments, which was already implemented in the provided code in `cell_id: f54347f1`. Since the system requested to 'generate the full fixed code again', I am providing the current, correct version of that cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "988631d9"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous instruction asked to modify the main execution block to select multiple quiz segments, which was already implemented in the provided code in `cell_id: f54347f1`. Since the system requested to 'generate the full fixed code again', I am providing the current, correct version of that cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f71f202d"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires saving all generated quiz JSON objects into a single 'all_quizzes.json' file. I need to modify the `map_llm_output_to_quiz_json` function to return the quiz data instead of writing to individual files, and then collect all quizzes in the main execution block before writing them to a single file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0dea52b"
      },
      "source": [
        "# Task\n",
        "Implement a new function `generate_rule_based_quiz(text_chunk: str, topic: str, all_noun_chunks: list)` to programmatically generate quiz questions and options based on the provided parameters. Additionally, extract all noun chunks from the entire `raw_transcript_data` to be used as a pool for incorrect options in the quiz generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd23931f"
      },
      "source": [
        "## Implement Rule-Based Quiz Generation\n",
        "\n",
        "### Subtask:\n",
        "Create a new function, `generate_rule_based_quiz(text_chunk: str, topic: str, all_noun_chunks: list)`, that programmatically generates a quiz. The question will be framed around the `topic`, and the correct option will be derived from the `topic` or a prominent phrase in the `text_chunk`. Three incorrect options will be selected from `all_noun_chunks` (other significant noun chunks from the *entire transcript* or current segment) or simple generic placeholders to ensure variety. The function will return a dictionary conforming to the `Question` Pydantic model structure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ce50afa"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires implementing the `generate_rule_based_quiz` function. This function will take a text chunk, a topic, and a list of all noun chunks to create a rule-based quiz question with one correct and three incorrect options, conforming to the `Question` Pydantic model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b6e309f"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code execution completed successfully after fixing the `NameError`, indicating that the task, which involved generating rule-based quizzes and saving them to a JSON file, has been accomplished.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a18a45dc",
        "outputId": "10a255b9-8bb5-4f54-c699-f459cfb87d19"
      },
      "source": [
        "import whisper_timestamped as whisper\n",
        "from moviepy.editor import VideoFileClip\n",
        "import json\n",
        "import os\n",
        "import spacy\n",
        "from pydantic import BaseModel, Field\n",
        "import random\n",
        "\n",
        "# --- CONFIGURATION (UPDATE THIS) ---\n",
        "# NOTE: Ensure this path points to a file you have uploaded or mounted in Colab.\n",
        "VIDEO_FILE_PATH = 'arrays.mp4'\n",
        "\n",
        "# Placeholder for Arya's LLM output - will be replaced by rule-based generation\n",
        "LLM_RAW_OUTPUT_STR = \"\"\"\n",
        "{\n",
        "    \"question\": \"Placeholder question\",\n",
        "    \"options\": [\n",
        "        {\"text\": \"Option A\", \"is_correct\": false},\n",
        "        {\"text\": \"Option B\", \"is_correct\": false},\n",
        "        {\"text\": \"Option C\", \"is_correct\": false},\n",
        "        {\"text\": \"Option D\", \"is_correct\": true}\n",
        "    ]\n",
        "}\n",
        "\"\"\"\n",
        "# --- END CONFIGURATION ---\n",
        "\n",
        "\n",
        "# --- LLM OUTPUT STRUCTURE (Day 4 Requirement) ---\n",
        "class QuizOption(BaseModel):\n",
        "    text: str = Field(description=\"The text of the answer option.\")\n",
        "    is_correct: bool = Field(description=\"True if this is the correct answer.\")\n",
        "\n",
        "class Question(BaseModel):\n",
        "    question: str = Field(description=\"The multiple-choice question text.\")\n",
        "    options: list[QuizOption] = Field(description=\"A list of 4 possible answers, with exactly one marked as correct.\")\n",
        "\n",
        "# --- INITIALIZE NLP MODEL (Day 3 Requirement) ---\n",
        "try:\n",
        "    # This assumes you ran the separate setup command: !python -m spacy download en_core_web_sm\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: spaCy model not loaded. Please run !python -m spacy download en_core_web_sm. Error: {e}\")\n",
        "    nlp = None\n",
        "\n",
        "\n",
        "# --- FUNCTION 1: DAY 2 - Transcription with Whisper ---\n",
        "def transcribe_video_with_timestamps(video_path: str, output_filename=\"transcript_raw.json\") -> dict:\n",
        "    \"\"\"Extracts audio, transcribes, and saves the raw Whisper output.\"\"\"\n",
        "\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"ERROR: Video file not found at path: {video_path}\")\n",
        "        return {}\n",
        "\n",
        "    temp_audio_path = \"temp_audio_mahesh.mp3\"\n",
        "\n",
        "    # 1. Extract audio from video\n",
        "    print(f\"DEBUG: Extracting audio from video: {video_path}...\")\n",
        "    try:\n",
        "        video_clip = VideoFileClip(video_path)\n",
        "        video_clip.audio.write_audiofile(temp_audio_path, logger=None)\n",
        "        video_clip.close()\n",
        "        print(f\"DEBUG: Audio successfully extracted to {temp_audio_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Audio extraction failed. Check FFMPEG or video format. Error: {e}\")\n",
        "        return {}\n",
        "\n",
        "    # 2. Load model and transcribe\n",
        "    print(\"Day 2 Task: Loading Whisper model ('small') and transcribing...\")\n",
        "    result = {}\n",
        "    try:\n",
        "        # Using 'small' model. Change to 'base' if 'small' is too slow.\n",
        "        model = whisper.load_model(\"small\")\n",
        "        result = whisper.transcribe(model, temp_audio_path, language=\"en\", verbose=False)\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Whisper transcription failed. Error: {e}\")\n",
        "        result = {}\n",
        "\n",
        "    # 3. SAVE OUTPUT TO FILE\n",
        "    if result:\n",
        "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(result, f, indent=4)\n",
        "        print(f\"\\n✅ Day 2 Output SAVED to {output_filename}\")\n",
        "\n",
        "    # Clean up the temporary audio file\n",
        "    if os.path.exists(temp_audio_path):\n",
        "        os.remove(temp_audio_path)\n",
        "        print(f\"DEBUG: Cleaned up temporary file: {temp_audio_path}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# --- FUNCTION 2: DAY 3 - NLP Topic Segmentation ---\n",
        "def detect_segment_topics(transcript_data: dict, output_filename=\"topic_timestamps.json\") -> list:\n",
        "    \"\"\"Analyzes each segment for key entities or noun chunks to determine quiz trigger points.\"\"\"\n",
        "    if not nlp:\n",
        "        print(\"ERROR: Cannot run detect_segment_topics. spaCy model not loaded.\")\n",
        "        return []\n",
        "\n",
        "    print(\"Day 3 Task: Running spaCy NER/Noun Chunk extraction for topic detection...\")\n",
        "    topic_segments = []\n",
        "    all_noun_chunks = [] # To collect all noun chunks for incorrect options\n",
        "\n",
        "    for segment in transcript_data.get('segments', []):\n",
        "        text = segment['text'].strip()\n",
        "        if not text:\n",
        "            continue\n",
        "\n",
        "        start_time = segment['start']\n",
        "        doc = nlp(text)\n",
        "\n",
        "        significant_noun_chunks = [\n",
        "            chunk.text for chunk in doc.noun_chunks\n",
        "            if not all(token.is_stop for token in chunk) and len(chunk.text.split()) > 1\n",
        "        ]\n",
        "        named_entities = [ent.text for ent in doc.ents]\n",
        "\n",
        "        current_segment_noun_chunks = list(set(named_entities + significant_noun_chunks))\n",
        "        all_noun_chunks.extend(current_segment_noun_chunks)\n",
        "\n",
        "        if current_segment_noun_chunks:\n",
        "            topic_segments.append({\n",
        "                \"start_sec\": int(start_time),\n",
        "                \"topic\": \" | \".join(sorted(current_segment_noun_chunks)),\n",
        "                \"text_chunk\": text\n",
        "            })\n",
        "\n",
        "    # Dedup and save all noun chunks for later use\n",
        "    all_noun_chunks = list(set(all_noun_chunks))\n",
        "    # SAVE OUTPUT TO FILE\n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(topic_segments, f, indent=4)\n",
        "    print(f\"\\n✅ Day 3 Output SAVED to {output_filename}\")\n",
        "\n",
        "    return topic_segments, all_noun_chunks # Return all_noun_chunks as well\n",
        "\n",
        "\n",
        "# --- FUNCTION: RULE-BASED QUIZ GENERATION ---\n",
        "def generate_rule_based_quiz(text_chunk: str, topic: str, all_noun_chunks: list) -> dict:\n",
        "    \"\"\"Programmatically generates a quiz question and options based on rules.\"\"\"\n",
        "\n",
        "    # 1. Formulate the question\n",
        "    question_text = f\"Which of the following best describes: {topic}?\"\n",
        "\n",
        "    # 2. Create the correct option\n",
        "    # For simplicity, let's use the topic itself as the correct option or a related phrase from the text_chunk\n",
        "    correct_option_text = topic.split(' | ')[0] if ' | ' in topic else topic # Use the first part if topic is combined\n",
        "    # Optionally, try to find a better phrasing from text_chunk that contains the topic\n",
        "    if correct_option_text.lower() not in text_chunk.lower():\n",
        "        # Fallback to a generic correct statement related to the topic if not directly found\n",
        "        correct_option_text = f\"Understanding the concept of {correct_option_text}\"\n",
        "\n",
        "    options = [QuizOption(text=correct_option_text, is_correct=True)]\n",
        "\n",
        "    # 3. Generate three incorrect options\n",
        "    potential_incorrect_options = [nc for nc in all_noun_chunks if nc != correct_option_text and nc not in topic.split(' | ')]\n",
        "    random.shuffle(potential_incorrect_options)\n",
        "\n",
        "    incorrect_count = 0\n",
        "    used_incorrect_options = set()\n",
        "\n",
        "    for opt in potential_incorrect_options:\n",
        "        if incorrect_count < 3 and opt not in used_incorrect_options:\n",
        "            options.append(QuizOption(text=opt, is_correct=False))\n",
        "            used_incorrect_options.add(opt)\n",
        "            incorrect_count += 1\n",
        "\n",
        "    # If not enough distinct noun chunks, use generic placeholders\n",
        "    generic_placeholders = [\n",
        "        \"Arrays are always dynamically sized\",\n",
        "        \"Linked lists offer faster random access\",\n",
        "        \"Space complexity is always O(1)\",\n",
        "        \"All data structures have the same performance characteristics\"\n",
        "    ]\n",
        "    random.shuffle(generic_placeholders)\n",
        "\n",
        "    for placeholder in generic_placeholders:\n",
        "        if incorrect_count < 3 and placeholder not in used_incorrect_options and placeholder != correct_option_text:\n",
        "            options.append(QuizOption(text=placeholder, is_correct=False))\n",
        "            used_incorrect_options.add(placeholder)\n",
        "            incorrect_count += 1\n",
        "\n",
        "    # Ensure exactly 4 options by adding more generic ones if necessary\n",
        "    while len(options) < 4:\n",
        "        # Pick a generic one not already used or similar to correct option\n",
        "        for placeholder in generic_placeholders:\n",
        "            if placeholder not in used_incorrect_options and placeholder != correct_option_text:\n",
        "                options.append(QuizOption(text=placeholder, is_correct=False))\n",
        "                used_incorrect_options.add(placeholder)\n",
        "                break\n",
        "        # If all generic are used, add a very generic one\n",
        "        if len(options) < 4:\n",
        "            options.append(QuizOption(text=f\"Some other irrelevant fact {len(options)}\", is_correct=False))\n",
        "\n",
        "\n",
        "    random.shuffle(options) # Shuffle to mix correct and incorrect options\n",
        "\n",
        "    # 4. Structure into Question Pydantic model\n",
        "    quiz_data = Question(\n",
        "        question=question_text,\n",
        "        options=options\n",
        "    )\n",
        "    return quiz_data.model_dump() # Return as dict\n",
        "\n",
        "\n",
        "# --- FUNCTION 3: DAY 4 - LLM Output Mapping ---\n",
        "def map_llm_output_to_quiz_json(llm_output_text: str, trigger_time_sec: int, quiz_index: int) -> dict:\n",
        "    \"\"\"Parses raw LLM JSON output into the final application JSON structure.\"\"\"\n",
        "\n",
        "    print(f\"Day 4 Task: Mapping LLM output to final structured JSON for quiz {quiz_index + 1}...\")\n",
        "\n",
        "    try:\n",
        "        # 1. Parse the LLM's JSON string output\n",
        "        llm_data = json.loads(llm_output_text)\n",
        "\n",
        "        # 2. Validate against Pydantic model\n",
        "        validated_question = Question(**llm_data)\n",
        "\n",
        "        # 3. Create the final required structure\n",
        "        final_quiz_data = {\n",
        "            \"id\": f\"quiz-{trigger_time_sec}-{quiz_index}\",\n",
        "            \"trigger_time_sec\": trigger_time_sec,\n",
        "            \"question\": validated_question.question,\n",
        "            # Use model_dump to convert Pydantic objects back to dicts\n",
        "            \"options\": [opt.model_dump() for opt in validated_question.options]\n",
        "        }\n",
        "\n",
        "        return final_quiz_data\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"ERROR: LLM output is not valid JSON. Check Arya's prompt structure.\")\n",
        "        return {}\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Pydantic validation or mapping failed: {e}\")\n",
        "        return {}\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# --- MAIN EXECUTION PIPELINE (Run this section) ---\n",
        "# --------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(f\"--- Running Full Mahesh Pipeline on: {VIDEO_FILE_PATH} ---\")\n",
        "\n",
        "    # 1. DAY 2 EXECUTION: Get raw transcription data\n",
        "    raw_transcript_data = transcribe_video_with_timestamps(VIDEO_FILE_PATH)\n",
        "\n",
        "    if raw_transcript_data:\n",
        "        # 2. DAY 3 EXECUTION: Find topic changes and collect all noun chunks\n",
        "        topic_list, all_noun_chunks = detect_segment_topics(raw_transcript_data)\n",
        "\n",
        "        if topic_list:\n",
        "            # Select up to 4 distinct quiz segments\n",
        "            selected_quiz_segments = topic_list[:min(len(topic_list), 4)]\n",
        "\n",
        "            print(f\"\\nSelected {len(selected_quiz_segments)} segments for quiz generation.\")\n",
        "\n",
        "            all_final_quizzes = []\n",
        "            for i, segment in enumerate(selected_quiz_segments):\n",
        "                trigger_time = segment['start_sec']\n",
        "                segment_topic = segment['topic']\n",
        "                segment_text_chunk = segment['text_chunk']\n",
        "\n",
        "                print(f\"\\nProcessing quiz for segment at {trigger_time} seconds (Topic: {segment_topic}).\")\n",
        "\n",
        "                # Use the new rule-based quiz generation function\n",
        "                generated_quiz = generate_rule_based_quiz(\n",
        "                    segment_text_chunk,\n",
        "                    segment_topic,\n",
        "                    all_noun_chunks\n",
        "                )\n",
        "\n",
        "                if generated_quiz:\n",
        "                    # Add id and trigger_time_sec to the generated quiz\n",
        "                    generated_quiz[\"id\"] = f\"quiz-{trigger_time}-{i}\"\n",
        "                    generated_quiz[\"trigger_time_sec\"] = trigger_time\n",
        "                    all_final_quizzes.append(generated_quiz)\n",
        "                else:\n",
        "                    print(f\"\\n❌ RULE-BASED QUIZ GENERATION FAILED for quiz {i + 1}.\")\n",
        "\n",
        "            if all_final_quizzes:\n",
        "                # Save all quizzes to a single file\n",
        "                output_filename_all_quizzes = \"all_quizzes.json\"\n",
        "                with open(output_filename_all_quizzes, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(all_final_quizzes, f, indent=4)\n",
        "                print(f\"\\n✅ All {len(all_final_quizzes)} quizzes SAVED to {output_filename_all_quizzes}\")\n",
        "\n",
        "                print(\"\\n--- All Final Quiz JSON Outputs (Preview) ---\")\n",
        "                print(json.dumps(all_final_quizzes, indent=4))\n",
        "                print(\"\\n\\n✅ FULL PIPELINE COMPLETE. Check your Colab file explorer for the 'all_quizzes.json' file.\")\n",
        "            else:\n",
        "                print(\"\\n❌ PIPELINE FAILED: No quizzes were successfully generated.\")\n",
        "        else:\n",
        "            print(\"\\n❌ PIPELINE FAILED at Day 3: No key topics/entities were detected.\")\n",
        "    else:\n",
        "        print(\"\\n❌ PIPELINE FAILED at Day 2: Transcription failed or video file was not found.\")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Full Mahesh Pipeline on: arrays.mp4 ---\n",
            "DEBUG: Extracting audio from video: arrays.mp4...\n",
            "DEBUG: Audio successfully extracted to temp_audio_mahesh.mp3\n",
            "Day 2 Task: Loading Whisper model ('small') and transcribing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5981/5981 [00:48<00:00, 122.06frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Day 2 Output SAVED to transcript_raw.json\n",
            "DEBUG: Cleaned up temporary file: temp_audio_mahesh.mp3\n",
            "Day 3 Task: Running spaCy NER/Noun Chunk extraction for topic detection...\n",
            "\n",
            "✅ Day 3 Output SAVED to topic_timestamps.json\n",
            "\n",
            "Selected 4 segments for quiz generation.\n",
            "\n",
            "Processing quiz for segment at 0 seconds (Topic: a data structure | firstly | the data | the form).\n",
            "\n",
            "Processing quiz for segment at 7 seconds (Topic: 1 | 10,4,2,99 | 2 | number 2 point array | similar type).\n",
            "\n",
            "Processing quiz for segment at 14 seconds (Topic: the integer type).\n",
            "\n",
            "Processing quiz for segment at 16 seconds (Topic: a separate array | floating value).\n",
            "\n",
            "✅ All 4 quizzes SAVED to all_quizzes.json\n",
            "\n",
            "--- All Final Quiz JSON Outputs (Preview) ---\n",
            "[\n",
            "    {\n",
            "        \"question\": \"Which of the following best describes: a data structure | firstly | the data | the form?\",\n",
            "        \"options\": [\n",
            "            {\n",
            "                \"text\": \"2\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"a data structure\",\n",
            "                \"is_correct\": true\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"99\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"floating value\",\n",
            "                \"is_correct\": false\n",
            "            }\n",
            "        ],\n",
            "        \"id\": \"quiz-0-0\",\n",
            "        \"trigger_time_sec\": 0\n",
            "    },\n",
            "    {\n",
            "        \"question\": \"Which of the following best describes: 1 | 10,4,2,99 | 2 | number 2 point array | similar type?\",\n",
            "        \"options\": [\n",
            "            {\n",
            "                \"text\": \"the integer type\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"1\",\n",
            "                \"is_correct\": true\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"0\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"fourth element\",\n",
            "                \"is_correct\": false\n",
            "            }\n",
            "        ],\n",
            "        \"id\": \"quiz-7-1\",\n",
            "        \"trigger_time_sec\": 7\n",
            "    },\n",
            "    {\n",
            "        \"question\": \"Which of the following best describes: the integer type?\",\n",
            "        \"options\": [\n",
            "            {\n",
            "                \"text\": \"the integer type\",\n",
            "                \"is_correct\": true\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"the array\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"1\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"fourth\",\n",
            "                \"is_correct\": false\n",
            "            }\n",
            "        ],\n",
            "        \"id\": \"quiz-14-2\",\n",
            "        \"trigger_time_sec\": 14\n",
            "    },\n",
            "    {\n",
            "        \"question\": \"Which of the following best describes: a separate array | floating value?\",\n",
            "        \"options\": [\n",
            "            {\n",
            "                \"text\": \"10,4,2,99\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"first\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"the form\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"a separate array\",\n",
            "                \"is_correct\": true\n",
            "            }\n",
            "        ],\n",
            "        \"id\": \"quiz-16-3\",\n",
            "        \"trigger_time_sec\": 16\n",
            "    }\n",
            "]\n",
            "\n",
            "\n",
            "✅ FULL PIPELINE COMPLETE. Check your Colab file explorer for the 'all_quizzes.json' file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0431f11b"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code execution successfully generated the quizzes and saved them to `all_quizzes.json`. The task is complete.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63992cd9",
        "outputId": "8d1a9ee8-963f-414f-fb63-94dbbfdd68ba"
      },
      "source": [
        "import whisper_timestamped as whisper\n",
        "from moviepy.editor import VideoFileClip\n",
        "import json\n",
        "import os\n",
        "import spacy\n",
        "from pydantic import BaseModel, Field\n",
        "import random\n",
        "\n",
        "# --- CONFIGURATION (UPDATE THIS) ---\n",
        "# NOTE: Ensure this path points to a file you have uploaded or mounted in Colab.\n",
        "VIDEO_FILE_PATH = 'arrays.mp4'\n",
        "\n",
        "# Placeholder for Arya's LLM output - will be replaced by rule-based generation\n",
        "LLM_RAW_OUTPUT_STR = \"\"\"\n",
        "{\n",
        "    \"question\": \"Placeholder question\",\n",
        "    \"options\": [\n",
        "        {\"text\": \"Option A\", \"is_correct\": false},\n",
        "        {\"text\": \"Option B\", \"is_correct\": false},\n",
        "        {\"text\": \"Option C\", \"is_correct\": false},\n",
        "        {\"text\": \"Option D\", \"is_correct\": true}\n",
        "    ]\n",
        "}\n",
        "\"\"\"\n",
        "# --- END CONFIGURATION ---\n",
        "\n",
        "\n",
        "# --- LLM OUTPUT STRUCTURE (Day 4 Requirement) ---\n",
        "class QuizOption(BaseModel):\n",
        "    text: str = Field(description=\"The text of the answer option.\")\n",
        "    is_correct: bool = Field(description=\"True if this is the correct answer.\")\n",
        "\n",
        "class Question(BaseModel):\n",
        "    question: str = Field(description=\"The multiple-choice question text.\")\n",
        "    options: list[QuizOption] = Field(description=\"A list of 4 possible answers, with exactly one marked as correct.\")\n",
        "\n",
        "# --- INITIALIZE NLP MODEL (Day 3 Requirement) ---\n",
        "try:\n",
        "    # This assumes you ran the separate setup command: !python -m spacy download en_core_web_sm\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: spaCy model not loaded. Please run !python -m spacy download en_core_web_sm. Error: {e}\")\n",
        "    nlp = None\n",
        "\n",
        "\n",
        "# --- FUNCTION 1: DAY 2 - Transcription with Whisper ---\n",
        "def transcribe_video_with_timestamps(video_path: str, output_filename=\"transcript_raw.json\") -> dict:\n",
        "    \"\"\"Extracts audio, transcribes, and saves the raw Whisper output.\"\"\"\n",
        "\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"ERROR: Video file not found at path: {video_path}\")\n",
        "        return {}\n",
        "\n",
        "    temp_audio_path = \"temp_audio_mahesh.mp3\"\n",
        "\n",
        "    # 1. Extract audio from video\n",
        "    print(f\"DEBUG: Extracting audio from video: {video_path}...\")\n",
        "    try:\n",
        "        video_clip = VideoFileClip(video_path)\n",
        "        video_clip.audio.write_audiofile(temp_audio_path, logger=None)\n",
        "        video_clip.close()\n",
        "        print(f\"DEBUG: Audio successfully extracted to {temp_audio_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Audio extraction failed. Check FFMPEG or video format. Error: {e}\")\n",
        "        return {}\n",
        "\n",
        "    # 2. Load model and transcribe\n",
        "    print(\"Day 2 Task: Loading Whisper model ('small') and transcribing...\")\n",
        "    result = {}\n",
        "    try:\n",
        "        # Using 'small' model. Change to 'base' if 'small' is too slow.\n",
        "        model = whisper.load_model(\"small\")\n",
        "        result = whisper.transcribe(model, temp_audio_path, language=\"en\", verbose=False)\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Whisper transcription failed. Error: {e}\")\n",
        "        result = {}\n",
        "\n",
        "    # 3. SAVE OUTPUT TO FILE\n",
        "    if result:\n",
        "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(result, f, indent=4)\n",
        "        print(f\"\\n✅ Day 2 Output SAVED to {output_filename}\")\n",
        "\n",
        "    # Clean up the temporary audio file\n",
        "    if os.path.exists(temp_audio_path):\n",
        "        os.remove(temp_audio_path)\n",
        "        print(f\"DEBUG: Cleaned up temporary file: {temp_audio_path}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# --- FUNCTION 2: DAY 3 - NLP Topic Segmentation ---\n",
        "def detect_segment_topics(transcript_data: dict, output_filename=\"topic_timestamps.json\") -> list:\n",
        "    \"\"\"Analyzes each segment for key entities or noun chunks to determine quiz trigger points.\"\"\"\n",
        "    if not nlp:\n",
        "        print(\"ERROR: Cannot run detect_segment_topics. spaCy model not loaded.\")\n",
        "        return []\n",
        "\n",
        "    print(\"Day 3 Task: Running spaCy NER/Noun Chunk extraction for topic detection...\")\n",
        "    topic_segments = []\n",
        "    all_noun_chunks = [] # To collect all noun chunks for incorrect options\n",
        "\n",
        "    for segment in transcript_data.get('segments', []):\n",
        "        text = segment['text'].strip()\n",
        "        if not text:\n",
        "            continue\n",
        "\n",
        "        start_time = segment['start']\n",
        "        doc = nlp(text)\n",
        "\n",
        "        significant_noun_chunks = [\n",
        "            chunk.text for chunk in doc.noun_chunks\n",
        "            if not all(token.is_stop for token in chunk) and len(chunk.text.split()) > 1\n",
        "        ]\n",
        "        named_entities = [ent.text for ent in doc.ents]\n",
        "\n",
        "        current_segment_noun_chunks = list(set(named_entities + significant_noun_chunks))\n",
        "        all_noun_chunks.extend(current_segment_noun_chunks)\n",
        "\n",
        "        if current_segment_noun_chunks:\n",
        "            topic_segments.append({\n",
        "                \"start_sec\": int(start_time),\n",
        "                \"topic\": \" | \".join(sorted(current_segment_noun_chunks)),\n",
        "                \"text_chunk\": text\n",
        "            })\n",
        "\n",
        "    # Dedup and save all noun chunks for later use\n",
        "    all_noun_chunks = list(set(all_noun_chunks))\n",
        "    # SAVE OUTPUT TO FILE\n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(topic_segments, f, indent=4)\n",
        "    print(f\"\\n✅ Day 3 Output SAVED to {output_filename}\")\n",
        "\n",
        "    return topic_segments, all_noun_chunks # Return all_noun_chunks as well\n",
        "\n",
        "\n",
        "# --- FUNCTION: RULE-BASED QUIZ GENERATION ---\n",
        "def generate_rule_based_quiz(text_chunk: str, topic: str, all_noun_chunks: list) -> dict:\n",
        "    \"\"\"Programmatically generates a quiz question and options based on rules.\"\"\"\n",
        "\n",
        "    # 1. Formulate the question\n",
        "    question_text = f\"Which of the following best describes: {topic}?\"\n",
        "\n",
        "    # 2. Create the correct option\n",
        "    # For simplicity, let's use the topic itself as the correct option or a related phrase from the text_chunk\n",
        "    correct_option_text = topic.split(' | ')[0] if ' | ' in topic else topic # Use the first part if topic is combined\n",
        "    # Optionally, try to find a better phrasing from text_chunk that contains the topic\n",
        "    if correct_option_text.lower() not in text_chunk.lower():\n",
        "        # Fallback to a generic correct statement related to the topic if not directly found\n",
        "        correct_option_text = f\"Understanding the concept of {correct_option_text}\"\n",
        "\n",
        "    options = [QuizOption(text=correct_option_text, is_correct=True)]\n",
        "\n",
        "    # 3. Generate three incorrect options\n",
        "    potential_incorrect_options = [nc for nc in all_noun_chunks if nc != correct_option_text and nc not in topic.split(' | ')]\n",
        "    random.shuffle(potential_incorrect_options)\n",
        "\n",
        "    incorrect_count = 0\n",
        "    used_incorrect_options = set()\n",
        "\n",
        "    for opt in potential_incorrect_options:\n",
        "        if incorrect_count < 3 and opt not in used_incorrect_options:\n",
        "            options.append(QuizOption(text=opt, is_correct=False))\n",
        "            used_incorrect_options.add(opt)\n",
        "            incorrect_count += 1\n",
        "\n",
        "    # If not enough distinct noun chunks, use generic placeholders\n",
        "    generic_placeholders = [\n",
        "        \"Arrays are always dynamically sized\",\n",
        "        \"Linked lists offer faster random access\",\n",
        "        \"Space complexity is always O(1)\",\n",
        "        \"All data structures have the same performance characteristics\"\n",
        "    ]\n",
        "    random.shuffle(generic_placeholders)\n",
        "\n",
        "    for placeholder in generic_placeholders:\n",
        "        if incorrect_count < 3 and placeholder not in used_incorrect_options and placeholder != correct_option_text:\n",
        "            options.append(QuizOption(text=placeholder, is_correct=False))\n",
        "            used_incorrect_options.add(placeholder)\n",
        "            incorrect_count += 1\n",
        "\n",
        "    # Ensure exactly 4 options by adding more generic ones if necessary\n",
        "    while len(options) < 4:\n",
        "        # Pick a generic one not already used or similar to correct option\n",
        "        for placeholder in generic_placeholders:\n",
        "            if placeholder not in used_incorrect_options and placeholder != correct_option_text:\n",
        "                options.append(QuizOption(text=placeholder, is_correct=False))\n",
        "                used_incorrect_options.add(placeholder)\n",
        "                break\n",
        "        # If all generic are used, add a very generic one\n",
        "        if len(options) < 4:\n",
        "            options.append(QuizOption(text=f\"Some other irrelevant fact {len(options)}\", is_correct=False))\n",
        "\n",
        "\n",
        "    random.shuffle(options) # Shuffle to mix correct and incorrect options\n",
        "\n",
        "    # 4. Structure into Question Pydantic model\n",
        "    quiz_data = Question(\n",
        "        question=question_text,\n",
        "        options=options\n",
        "    )\n",
        "    return quiz_data.model_dump() # Return as dict\n",
        "\n",
        "\n",
        "# --- FUNCTION 3: DAY 4 - LLM Output Mapping ---\n",
        "def map_llm_output_to_quiz_json(llm_output_text: str, trigger_time_sec: int, quiz_index: int) -> dict:\n",
        "    \"\"\"Parses raw LLM JSON output into the final application JSON structure.\"\"\"\n",
        "\n",
        "    print(f\"Day 4 Task: Mapping LLM output to final structured JSON for quiz {quiz_index + 1}...\")\n",
        "\n",
        "    try:\n",
        "        # 1. Parse the LLM's JSON string output\n",
        "        llm_data = json.loads(llm_output_text)\n",
        "\n",
        "        # 2. Validate against Pydantic model\n",
        "        validated_question = Question(**llm_data)\n",
        "\n",
        "        # 3. Create the final required structure\n",
        "        final_quiz_data = {\n",
        "            \"id\": f\"quiz-{trigger_time_sec}-{quiz_index}\",\n",
        "            \"trigger_time_sec\": trigger_time_sec,\n",
        "            \"question\": validated_question.question,\n",
        "            # Use model_dump to convert Pydantic objects back to dicts\n",
        "            \"options\": [opt.model_dump() for opt in validated_question.options]\n",
        "        }\n",
        "\n",
        "        return final_quiz_data\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"ERROR: LLM output is not valid JSON. Check Arya's prompt structure.\")\n",
        "        return {}\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Pydantic validation or mapping failed: {e}\")\n",
        "        return {}\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# --- MAIN EXECUTION PIPELINE (Run this section) ---\n",
        "# --------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(f\"--- Running Full Mahesh Pipeline on: {VIDEO_FILE_PATH} ---\")\n",
        "\n",
        "    # 1. DAY 2 EXECUTION: Get raw transcription data\n",
        "    raw_transcript_data = transcribe_video_with_timestamps(VIDEO_FILE_PATH)\n",
        "\n",
        "    if raw_transcript_data:\n",
        "        # 2. DAY 3 EXECUTION: Find topic changes and collect all noun chunks\n",
        "        topic_list, all_noun_chunks = detect_segment_topics(raw_transcript_data)\n",
        "\n",
        "        if topic_list:\n",
        "            # Select up to 4 distinct quiz segments\n",
        "            selected_quiz_segments = topic_list[:min(len(topic_list), 4)]\n",
        "\n",
        "            print(f\"\\nSelected {len(selected_quiz_segments)} segments for quiz generation.\")\n",
        "\n",
        "            all_final_quizzes = []\n",
        "            for i, segment in enumerate(selected_quiz_segments):\n",
        "                trigger_time = segment['start_sec']\n",
        "                segment_topic = segment['topic']\n",
        "                segment_text_chunk = segment['text_chunk']\n",
        "\n",
        "                print(f\"\\nProcessing quiz for segment at {trigger_time} seconds (Topic: {segment_topic}).\")\n",
        "\n",
        "                # Use the new rule-based quiz generation function\n",
        "                generated_quiz = generate_rule_based_quiz(\n",
        "                    segment_text_chunk,\n",
        "                    segment_topic,\n",
        "                    all_noun_chunks\n",
        "                )\n",
        "\n",
        "                if generated_quiz:\n",
        "                    # Add id and trigger_time_sec to the generated quiz\n",
        "                    generated_quiz[\"id\"] = f\"quiz-{trigger_time}-{i}\"\n",
        "                    generated_quiz[\"trigger_time_sec\"] = trigger_time\n",
        "                    all_final_quizzes.append(generated_quiz)\n",
        "                else:\n",
        "                    print(f\"\\n❌ RULE-BASED QUIZ GENERATION FAILED for quiz {i + 1}.\")\n",
        "\n",
        "            if all_final_quizzes:\n",
        "                # Save all quizzes to a single file\n",
        "                output_filename_all_quizzes = \"all_quizzes.json\"\n",
        "                with open(output_filename_all_quizzes, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(all_final_quizzes, f, indent=4)\n",
        "                print(f\"\\n✅ All {len(all_final_quizzes)} quizzes SAVED to {output_filename_all_quizzes}\")\n",
        "\n",
        "                print(\"\\n--- All Final Quiz JSON Outputs (Preview) ---\")\n",
        "                print(json.dumps(all_final_quizzes, indent=4))\n",
        "                print(\"\\n\\n✅ FULL PIPELINE COMPLETE. Check your Colab file explorer for the 'all_quizzes.json' file.\")\n",
        "            else:\n",
        "                print(\"\\n❌ PIPELINE FAILED: No quizzes were successfully generated.\")\n",
        "        else:\n",
        "            print(\"\\n❌ PIPELINE FAILED at Day 3: No key topics/entities were detected.\")\n",
        "    else:\n",
        "        print(\"\\n❌ PIPELINE FAILED at Day 2: Transcription failed or video file was not found.\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Full Mahesh Pipeline on: arrays.mp4 ---\n",
            "DEBUG: Extracting audio from video: arrays.mp4...\n",
            "DEBUG: Audio successfully extracted to temp_audio_mahesh.mp3\n",
            "Day 2 Task: Loading Whisper model ('small') and transcribing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5981/5981 [00:48<00:00, 122.95frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Day 2 Output SAVED to transcript_raw.json\n",
            "DEBUG: Cleaned up temporary file: temp_audio_mahesh.mp3\n",
            "Day 3 Task: Running spaCy NER/Noun Chunk extraction for topic detection...\n",
            "\n",
            "✅ Day 3 Output SAVED to topic_timestamps.json\n",
            "\n",
            "Selected 4 segments for quiz generation.\n",
            "\n",
            "Processing quiz for segment at 0 seconds (Topic: a data structure | firstly | the data | the form).\n",
            "\n",
            "Processing quiz for segment at 7 seconds (Topic: 1 | 10,4,2,99 | 2 | number 2 point array | similar type).\n",
            "\n",
            "Processing quiz for segment at 14 seconds (Topic: the integer type).\n",
            "\n",
            "Processing quiz for segment at 16 seconds (Topic: a separate array | floating value).\n",
            "\n",
            "✅ All 4 quizzes SAVED to all_quizzes.json\n",
            "\n",
            "--- All Final Quiz JSON Outputs (Preview) ---\n",
            "[\n",
            "    {\n",
            "        \"question\": \"Which of the following best describes: a data structure | firstly | the data | the form?\",\n",
            "        \"options\": [\n",
            "            {\n",
            "                \"text\": \"floating value\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"a data structure\",\n",
            "                \"is_correct\": true\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"number 4 point array\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"more such videos\",\n",
            "                \"is_correct\": false\n",
            "            }\n",
            "        ],\n",
            "        \"id\": \"quiz-0-0\",\n",
            "        \"trigger_time_sec\": 0\n",
            "    },\n",
            "    {\n",
            "        \"question\": \"Which of the following best describes: 1 | 10,4,2,99 | 2 | number 2 point array | similar type?\",\n",
            "        \"options\": [\n",
            "            {\n",
            "                \"text\": \"1\",\n",
            "                \"is_correct\": true\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"a data structure\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"1 element\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"first element\",\n",
            "                \"is_correct\": false\n",
            "            }\n",
            "        ],\n",
            "        \"id\": \"quiz-7-1\",\n",
            "        \"trigger_time_sec\": 7\n",
            "    },\n",
            "    {\n",
            "        \"question\": \"Which of the following best describes: the integer type?\",\n",
            "        \"options\": [\n",
            "            {\n",
            "                \"text\": \"the integer type\",\n",
            "                \"is_correct\": true\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"fourth\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"0\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"fourth element\",\n",
            "                \"is_correct\": false\n",
            "            }\n",
            "        ],\n",
            "        \"id\": \"quiz-14-2\",\n",
            "        \"trigger_time_sec\": 14\n",
            "    },\n",
            "    {\n",
            "        \"question\": \"Which of the following best describes: a separate array | floating value?\",\n",
            "        \"options\": [\n",
            "            {\n",
            "                \"text\": \"a separate array\",\n",
            "                \"is_correct\": true\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"0\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"99\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"first\",\n",
            "                \"is_correct\": false\n",
            "            }\n",
            "        ],\n",
            "        \"id\": \"quiz-16-3\",\n",
            "        \"trigger_time_sec\": 16\n",
            "    }\n",
            "]\n",
            "\n",
            "\n",
            "✅ FULL PIPELINE COMPLETE. Check your Colab file explorer for the 'all_quizzes.json' file.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6faf8431"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code execution successfully generated the quizzes and saved them to `all_quizzes.json`. The task is complete.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c78ff0c",
        "outputId": "1c4f74ad-731d-4fc5-d7f0-21889948689d"
      },
      "source": [
        "import whisper_timestamped as whisper\n",
        "from moviepy.editor import VideoFileClip\n",
        "import json\n",
        "import os\n",
        "import spacy\n",
        "from pydantic import BaseModel, Field\n",
        "import random\n",
        "\n",
        "# --- CONFIGURATION (UPDATE THIS) ---\n",
        "# NOTE: Ensure this path points to a file you have uploaded or mounted in Colab.\n",
        "VIDEO_FILE_PATH = 'arrays.mp4'\n",
        "\n",
        "# Placeholder for Arya's LLM output - will be replaced by rule-based generation\n",
        "LLM_RAW_OUTPUT_STR = \"\"\"\n",
        "{\n",
        "    \"question\": \"Placeholder question\",\n",
        "    \"options\": [\n",
        "        {\"text\": \"Option A\", \"is_correct\": false},\n",
        "        {\"text\": \"Option B\", \"is_correct\": false},\n",
        "        {\"text\": \"Option C\", \"is_correct\": false},\n",
        "        {\"text\": \"Option D\", \"is_correct\": true}\n",
        "    ]\n",
        "}\n",
        "\"\"\"\n",
        "# --- END CONFIGURATION ---\n",
        "\n",
        "\n",
        "# --- LLM OUTPUT STRUCTURE (Day 4 Requirement) ---\n",
        "class QuizOption(BaseModel):\n",
        "    text: str = Field(description=\"The text of the answer option.\")\n",
        "    is_correct: bool = Field(description=\"True if this is the correct answer.\")\n",
        "\n",
        "class Question(BaseModel):\n",
        "    question: str = Field(description=\"The multiple-choice question text.\")\n",
        "    options: list[QuizOption] = Field(description=\"A list of 4 possible answers, with exactly one marked as correct.\")\n",
        "\n",
        "# --- INITIALIZE NLP MODEL (Day 3 Requirement) ---\n",
        "try:\n",
        "    # This assumes you ran the separate setup command: !python -m spacy download en_core_web_sm\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: spaCy model not loaded. Please run !python -m spacy download en_core_web_sm. Error: {e}\")\n",
        "    nlp = None\n",
        "\n",
        "\n",
        "# --- FUNCTION 1: DAY 2 - Transcription with Whisper ---\n",
        "def transcribe_video_with_timestamps(video_path: str, output_filename=\"transcript_raw.json\") -> dict:\n",
        "    \"\"\"Extracts audio, transcribes, and saves the raw Whisper output.\"\"\"\n",
        "\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"ERROR: Video file not found at path: {video_path}\")\n",
        "        return {}\n",
        "\n",
        "    temp_audio_path = \"temp_audio_mahesh.mp3\"\n",
        "\n",
        "    # 1. Extract audio from video\n",
        "    print(f\"DEBUG: Extracting audio from video: {video_path}...\")\n",
        "    try:\n",
        "        video_clip = VideoFileClip(video_path)\n",
        "        video_clip.audio.write_audiofile(temp_audio_path, logger=None)\n",
        "        video_clip.close()\n",
        "        print(f\"DEBUG: Audio successfully extracted to {temp_audio_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Audio extraction failed. Check FFMPEG or video format. Error: {e}\")\n",
        "        return {}\n",
        "\n",
        "    # 2. Load model and transcribe\n",
        "    print(\"Day 2 Task: Loading Whisper model ('small') and transcribing...\")\n",
        "    result = {}\n",
        "    try:\n",
        "        # Using 'small' model. Change to 'base' if 'small' is too slow.\n",
        "        model = whisper.load_model(\"small\")\n",
        "        result = whisper.transcribe(model, temp_audio_path, language=\"en\", verbose=False)\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Whisper transcription failed. Error: {e}\")\n",
        "        result = {}\n",
        "\n",
        "    # 3. SAVE OUTPUT TO FILE\n",
        "    if result:\n",
        "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(result, f, indent=4)\n",
        "        print(f\"\\n✅ Day 2 Output SAVED to {output_filename}\")\n",
        "\n",
        "    # Clean up the temporary audio file\n",
        "    if os.path.exists(temp_audio_path):\n",
        "        os.remove(temp_audio_path)\n",
        "        print(f\"DEBUG: Cleaned up temporary file: {temp_audio_path}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# --- FUNCTION 2: DAY 3 - NLP Topic Segmentation ---\n",
        "def detect_segment_topics(transcript_data: dict, output_filename=\"topic_timestamps.json\") -> list:\n",
        "    \"\"\"Analyzes each segment for key entities or noun chunks to determine quiz trigger points.\"\"\"\n",
        "    if not nlp:\n",
        "        print(\"ERROR: Cannot run detect_segment_topics. spaCy model not loaded.\")\n",
        "        return []\n",
        "\n",
        "    print(\"Day 3 Task: Running spaCy NER/Noun Chunk extraction for topic detection...\")\n",
        "    topic_segments = []\n",
        "    all_noun_chunks = [] # To collect all noun chunks for incorrect options\n",
        "\n",
        "    for segment in transcript_data.get('segments', []):\n",
        "        text = segment['text'].strip()\n",
        "        if not text:\n",
        "            continue\n",
        "\n",
        "        start_time = segment['start']\n",
        "        doc = nlp(text)\n",
        "\n",
        "        significant_noun_chunks = [\n",
        "            chunk.text for chunk in doc.noun_chunks\n",
        "            if not all(token.is_stop for token in chunk) and len(chunk.text.split()) > 1\n",
        "        ]\n",
        "        named_entities = [ent.text for ent in doc.ents]\n",
        "\n",
        "        current_segment_noun_chunks = list(set(named_entities + significant_noun_chunks))\n",
        "        all_noun_chunks.extend(current_segment_noun_chunks)\n",
        "\n",
        "        if current_segment_noun_chunks:\n",
        "            topic_segments.append({\n",
        "                \"start_sec\": int(start_time),\n",
        "                \"topic\": \" | \".join(sorted(current_segment_noun_chunks)),\n",
        "                \"text_chunk\": text\n",
        "            })\n",
        "\n",
        "    # Dedup and save all noun chunks for later use\n",
        "    all_noun_chunks = list(set(all_noun_chunks))\n",
        "    # SAVE OUTPUT TO FILE\n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(topic_segments, f, indent=4)\n",
        "    print(f\"\\n✅ Day 3 Output SAVED to {output_filename}\")\n",
        "\n",
        "    return topic_segments, all_noun_chunks # Return all_noun_chunks as well\n",
        "\n",
        "\n",
        "# --- FUNCTION: RULE-BASED QUIZ GENERATION ---\n",
        "def generate_rule_based_quiz(text_chunk: str, topic: str, all_noun_chunks: list) -> dict:\n",
        "    \"\"\"Programmatically generates a quiz question and options based on rules.\"\"\"\n",
        "\n",
        "    # 1. Formulate the question\n",
        "    question_text = f\"Which of the following best describes: {topic}?\"\n",
        "\n",
        "    # 2. Create the correct option\n",
        "    # For simplicity, let's use the topic itself as the correct option or a related phrase from the text_chunk\n",
        "    correct_option_text = topic.split(' | ')[0] if ' | ' in topic else topic # Use the first part if topic is combined\n",
        "    # Optionally, try to find a better phrasing from text_chunk that contains the topic\n",
        "    if correct_option_text.lower() not in text_chunk.lower():\n",
        "        # Fallback to a generic correct statement related to the topic if not directly found\n",
        "        correct_option_text = f\"Understanding the concept of {correct_option_text}\"\n",
        "\n",
        "    options = [QuizOption(text=correct_option_text, is_correct=True)]\n",
        "\n",
        "    # 3. Generate three incorrect options\n",
        "    potential_incorrect_options = [nc for nc in all_noun_chunks if nc != correct_option_text and nc not in topic.split(' | ')]\n",
        "    random.shuffle(potential_incorrect_options)\n",
        "\n",
        "    incorrect_count = 0\n",
        "    used_incorrect_options = set()\n",
        "\n",
        "    for opt in potential_incorrect_options:\n",
        "        if incorrect_count < 3 and opt not in used_incorrect_options:\n",
        "            options.append(QuizOption(text=opt, is_correct=False))\n",
        "            used_incorrect_options.add(opt)\n",
        "            incorrect_count += 1\n",
        "\n",
        "    # If not enough distinct noun chunks, use generic placeholders\n",
        "    generic_placeholders = [\n",
        "        \"Arrays are always dynamically sized\",\n",
        "        \"Linked lists offer faster random access\",\n",
        "        \"Space complexity is always O(1)\",\n",
        "        \"All data structures have the same performance characteristics\"\n",
        "    ]\n",
        "    random.shuffle(generic_placeholders)\n",
        "\n",
        "    for placeholder in generic_placeholders:\n",
        "        if incorrect_count < 3 and placeholder not in used_incorrect_options and placeholder != correct_option_text:\n",
        "            options.append(QuizOption(text=placeholder, is_correct=False))\n",
        "            used_incorrect_options.add(placeholder)\n",
        "            incorrect_count += 1\n",
        "\n",
        "    # Ensure exactly 4 options by adding more generic ones if necessary\n",
        "    while len(options) < 4:\n",
        "        # Pick a generic one not already used or similar to correct option\n",
        "        for placeholder in generic_placeholders:\n",
        "            if placeholder not in used_incorrect_options and placeholder != correct_option_text:\n",
        "                options.append(QuizOption(text=placeholder, is_correct=False))\n",
        "                used_incorrect_options.add(placeholder)\n",
        "                break\n",
        "        # If all generic are used, add a very generic one\n",
        "        if len(options) < 4:\n",
        "            options.append(QuizOption(text=f\"Some other irrelevant fact {len(options)}\", is_correct=False))\n",
        "\n",
        "\n",
        "    random.shuffle(options) # Shuffle to mix correct and incorrect options\n",
        "\n",
        "    # 4. Structure into Question Pydantic model\n",
        "    quiz_data = Question(\n",
        "        question=question_text,\n",
        "        options=options\n",
        "    )\n",
        "    return quiz_data.model_dump() # Return as dict\n",
        "\n",
        "\n",
        "# --- FUNCTION 3: DAY 4 - LLM Output Mapping ---\n",
        "def map_llm_output_to_quiz_json(llm_output_text: str, trigger_time_sec: int, quiz_index: int) -> dict:\n",
        "    \"\"\"Parses raw LLM JSON output into the final application JSON structure.\"\"\"\n",
        "\n",
        "    print(f\"Day 4 Task: Mapping LLM output to final structured JSON for quiz {quiz_index + 1}...\")\n",
        "\n",
        "    try:\n",
        "        # 1. Parse the LLM's JSON string output\n",
        "        llm_data = json.loads(llm_output_text)\n",
        "\n",
        "        # 2. Validate against Pydantic model\n",
        "        validated_question = Question(**llm_data)\n",
        "\n",
        "        # 3. Create the final required structure\n",
        "        final_quiz_data = {\n",
        "            \"id\": f\"quiz-{trigger_time_sec}-{quiz_index}\",\n",
        "            \"trigger_time_sec\": trigger_time_sec,\n",
        "            \"question\": validated_question.question,\n",
        "            # Use model_dump to convert Pydantic objects back to dicts\n",
        "            \"options\": [opt.model_dump() for opt in validated_question.options]\n",
        "        }\n",
        "\n",
        "        return final_quiz_data\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"ERROR: LLM output is not valid JSON. Check Arya's prompt structure.\")\n",
        "        return {}\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Pydantic validation or mapping failed: {e}\")\n",
        "        return {}\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# --- MAIN EXECUTION PIPELINE (Run this section) ---\n",
        "# --------------------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(f\"--- Running Full Mahesh Pipeline on: {VIDEO_FILE_PATH} ---\")\n",
        "\n",
        "    # 1. DAY 2 EXECUTION: Get raw transcription data\n",
        "    raw_transcript_data = transcribe_video_with_timestamps(VIDEO_FILE_PATH)\n",
        "\n",
        "    if raw_transcript_data:\n",
        "        # 2. DAY 3 EXECUTION: Find topic changes and collect all noun chunks\n",
        "        topic_list, all_noun_chunks = detect_segment_topics(raw_transcript_data)\n",
        "\n",
        "        if topic_list:\n",
        "            # Select up to 4 distinct quiz segments\n",
        "            selected_quiz_segments = topic_list[:min(len(topic_list), 4)]\n",
        "\n",
        "            print(f\"\\nSelected {len(selected_quiz_segments)} segments for quiz generation.\")\n",
        "\n",
        "            all_final_quizzes = []\n",
        "            for i, segment in enumerate(selected_quiz_segments):\n",
        "                trigger_time = segment['start_sec']\n",
        "                segment_topic = segment['topic']\n",
        "                segment_text_chunk = segment['text_chunk']\n",
        "\n",
        "                print(f\"\\nProcessing quiz for segment at {trigger_time} seconds (Topic: {segment_topic}).\")\n",
        "\n",
        "                # Use the new rule-based quiz generation function\n",
        "                generated_quiz = generate_rule_based_quiz(\n",
        "                    segment_text_chunk,\n",
        "                    segment_topic,\n",
        "                    all_noun_chunks\n",
        "                )\n",
        "\n",
        "                if generated_quiz:\n",
        "                    # Add id and trigger_time_sec to the generated quiz\n",
        "                    generated_quiz[\"id\"] = f\"quiz-{trigger_time}-{i}\"\n",
        "                    generated_quiz[\"trigger_time_sec\"] = trigger_time\n",
        "                    all_final_quizzes.append(generated_quiz)\n",
        "                else:\n",
        "                    print(f\"\\n❌ RULE-BASED QUIZ GENERATION FAILED for quiz {i + 1}.\")\n",
        "\n",
        "            if all_final_quizzes:\n",
        "                # Save all quizzes to a single file\n",
        "                output_filename_all_quizzes = \"all_quizzes.json\"\n",
        "                with open(output_filename_all_quizzes, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(all_final_quizzes, f, indent=4)\n",
        "                print(f\"\\n✅ All {len(all_final_quizzes)} quizzes SAVED to {output_filename_all_quizzes}\")\n",
        "\n",
        "                print(\"\\n--- All Final Quiz JSON Outputs (Preview) ---\")\n",
        "                print(json.dumps(all_final_quizzes, indent=4))\n",
        "                print(\"\\n\\n✅ FULL PIPELINE COMPLETE. Check your Colab file explorer for the 'all_quizzes.json' file.\")\n",
        "            else:\n",
        "                print(\"\\n❌ PIPELINE FAILED: No quizzes were successfully generated.\")\n",
        "        else:\n",
        "            print(\"\\n❌ PIPELINE FAILED at Day 3: No key topics/entities were detected.\")\n",
        "    else:\n",
        "        print(\"\\n❌ PIPELINE FAILED at Day 2: Transcription failed or video file was not found.\")\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running Full Mahesh Pipeline on: arrays.mp4 ---\n",
            "DEBUG: Extracting audio from video: arrays.mp4...\n",
            "DEBUG: Audio successfully extracted to temp_audio_mahesh.mp3\n",
            "Day 2 Task: Loading Whisper model ('small') and transcribing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5981/5981 [00:51<00:00, 115.79frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Day 2 Output SAVED to transcript_raw.json\n",
            "DEBUG: Cleaned up temporary file: temp_audio_mahesh.mp3\n",
            "Day 3 Task: Running spaCy NER/Noun Chunk extraction for topic detection...\n",
            "\n",
            "✅ Day 3 Output SAVED to topic_timestamps.json\n",
            "\n",
            "Selected 4 segments for quiz generation.\n",
            "\n",
            "Processing quiz for segment at 0 seconds (Topic: a data structure | firstly | the data | the form).\n",
            "\n",
            "Processing quiz for segment at 7 seconds (Topic: 1 | 10,4,2,99 | 2 | number 2 point array | similar type).\n",
            "\n",
            "Processing quiz for segment at 14 seconds (Topic: the integer type).\n",
            "\n",
            "Processing quiz for segment at 16 seconds (Topic: a separate array | floating value).\n",
            "\n",
            "✅ All 4 quizzes SAVED to all_quizzes.json\n",
            "\n",
            "--- All Final Quiz JSON Outputs (Preview) ---\n",
            "[\n",
            "    {\n",
            "        \"question\": \"Which of the following best describes: a data structure | firstly | the data | the form?\",\n",
            "        \"options\": [\n",
            "            {\n",
            "                \"text\": \"fourth element\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"more such videos\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"0\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"a data structure\",\n",
            "                \"is_correct\": true\n",
            "            }\n",
            "        ],\n",
            "        \"id\": \"quiz-0-0\",\n",
            "        \"trigger_time_sec\": 0\n",
            "    },\n",
            "    {\n",
            "        \"question\": \"Which of the following best describes: 1 | 10,4,2,99 | 2 | number 2 point array | similar type?\",\n",
            "        \"options\": [\n",
            "            {\n",
            "                \"text\": \"99\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"the element\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"1\",\n",
            "                \"is_correct\": true\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"fourth element\",\n",
            "                \"is_correct\": false\n",
            "            }\n",
            "        ],\n",
            "        \"id\": \"quiz-7-1\",\n",
            "        \"trigger_time_sec\": 7\n",
            "    },\n",
            "    {\n",
            "        \"question\": \"Which of the following best describes: the integer type?\",\n",
            "        \"options\": [\n",
            "            {\n",
            "                \"text\": \"3\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"the array\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"the integer type\",\n",
            "                \"is_correct\": true\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"number 4 point array\",\n",
            "                \"is_correct\": false\n",
            "            }\n",
            "        ],\n",
            "        \"id\": \"quiz-14-2\",\n",
            "        \"trigger_time_sec\": 14\n",
            "    },\n",
            "    {\n",
            "        \"question\": \"Which of the following best describes: a separate array | floating value?\",\n",
            "        \"options\": [\n",
            "            {\n",
            "                \"text\": \"2\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"10,4,2,99\",\n",
            "                \"is_correct\": false\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"a separate array\",\n",
            "                \"is_correct\": true\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"4\",\n",
            "                \"is_correct\": false\n",
            "            }\n",
            "        ],\n",
            "        \"id\": \"quiz-16-3\",\n",
            "        \"trigger_time_sec\": 16\n",
            "    }\n",
            "]\n",
            "\n",
            "\n",
            "✅ FULL PIPELINE COMPLETE. Check your Colab file explorer for the 'all_quizzes.json' file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gQs3Xkyhc5wd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGp1/9rttrceG/tuWBhgSh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}